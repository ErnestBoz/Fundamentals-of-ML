{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43008855",
   "metadata": {},
   "source": [
    "# Answer template\n",
    "\n",
    "Please use this notebook for your coursework. Feel free to add more cells for your code and answers, but try to stick to this format. This will make it easier to mark everyone's work fairly.\n",
    "\n",
    "___________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab73d0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this\n",
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577fc01e",
   "metadata": {},
   "source": [
    "# Part A – Exploratory data analysis and data visualisation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1f6b5f",
   "metadata": {},
   "source": [
    "1. Using the pandas library, read the file dataset1.csv into a dataframe. Print or display the first five rows of the dataset. [1 mark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa9f9380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114ace7d",
   "metadata": {},
   "source": [
    "2. Make a scatterplot from the dataset, with the Longitude column on the x axis, the Latitude column on the y axis, and the colour corresponding to the Monastery_index column. Within the scatterplot function, set the colour map to ’rainbow’. The result should be a scatterplot showing the position of every monastery, with different colours for monasteries with different values in Monastery_index.  [1 mark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeba955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a00d3b",
   "metadata": {},
   "source": [
    "3. Plot a histogram for the monastery starting year of activity, represented in the Starting column.\n",
    "Add the title “Starting year” to the plot. [1 mark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a030570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6eeb7b",
   "metadata": {},
   "source": [
    "4. Make a figure with two histograms, still using the Starting column:\n",
    "\n",
    "a) One histogram representing the Cistercian monasteries, corresponding to rows in the dataframe where the Monastery column is equal to 'Cistercians'.\n",
    "\n",
    "b) And one histogram representing the Franciscan monasteries, corresponding to rows in the dataframe where the Monastery column is equal to 'Franciscans'.\n",
    "\n",
    "c) Add a legend indicating which histogram corresponds to which type of monastery.\n",
    "\n",
    "d) Add the title “Starting year” to the figure. \n",
    "\n",
    "[2 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b613829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8631d612",
   "metadata": {},
   "source": [
    "5. Repeat numbers 3 and 4, but for the Ending column. Add the title “Ending year” to the plot.\n",
    "[2 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f9548b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26ddc9f",
   "metadata": {},
   "source": [
    "6. Count the number of times each country appears in the Country column. Use that to make a bar plot, showing one bar for each country, with the bar height representing how many times each country appears in the Country column. This corresponds to the number of monasteries found in each country.\n",
    "[2 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509c0cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b4da81",
   "metadata": {},
   "source": [
    "_____________________\n",
    "\n",
    "# Part B – Training classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa6bdc0",
   "metadata": {},
   "source": [
    "7.\tDefine a variable X corresponding to the Starting and Ending columns of the dataset, and a variable y corresponding to the Monastery_index column. [1 mark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d7a64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378f0caa",
   "metadata": {},
   "source": [
    "8.\tPerform a train-test split, separating X and y into a training test and a test set, leaving 33% of the data in the test set. [1 mark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512bb7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8724663d",
   "metadata": {},
   "source": [
    "9.\tClassification using a Perceptron:\n",
    "\n",
    "a)\tFit a perceptron to the training data, and use it to predict y values for the test set.\n",
    "[1 mark]\n",
    "\n",
    "b)\tCalculate the fraction of data points in the test set where the predicted y values and the actual y values differ. This fraction should be equal to zero if the prediction is perfect, and equal to 1 if the prediction is wrong for 100% of the test set. Print the value of that fraction in decimals (like 0.01, 0.2394, or 0.9999923).  [2 marks]\n",
    "\n",
    "c)\tPlot a confusion matrix showing how well the classifier performs on the test set. [1 mark]\n",
    "\n",
    "d)\tTreating “Franciscan” as “Positive” and “Cistercian” as “Negative”, Print out the precision, recall, accuracy and F1 score of the perceptron. [2 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da90210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508e60f2",
   "metadata": {},
   "source": [
    "10.\tClassification using Logistic Regression: do the same as the question above, but using the logistic regression classifier. [4 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df609bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634bb1eb",
   "metadata": {},
   "source": [
    "For open-ended questions like the ones below, write your answers in a new cell of code, either as a commented-out line starting with #, or as a markdown cell. Indicate what question you’re answering, by copying the question as well. For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d87f644",
   "metadata": {},
   "source": [
    "11.\tExplain the importance of the train-test split in machine learning. What might happen if you don’t have a proper split? [ 2 marks ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfafc3a",
   "metadata": {},
   "source": [
    "**>>> Answer by editing this cell (double-click here)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8883f",
   "metadata": {},
   "source": [
    "12.\tWhich classifier (Perceptron or Logistic Regression) performed better at this task? Explain how you’ve arrived at this answer. [4 marks] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac4db9a",
   "metadata": {},
   "source": [
    "**>>> Answer by editing this cell (double-click here)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28a0f8f",
   "metadata": {},
   "source": [
    "13.\tIf you run the code from questions 8, 9, and 10 again, do the scores (precision, recall, accuracy, F1) change? Why (or why not)? Explain where those scores come from, and how do they change (or don't change) if you run the code again. [3 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2f3ad2",
   "metadata": {},
   "source": [
    "**>>> Answer by editing this cell (double-click here)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ed695e",
   "metadata": {},
   "source": [
    "_______________\n",
    "\n",
    "# Part C – Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e6e136",
   "metadata": {},
   "source": [
    "14. Read the file `dataset2.csv` into a dataframe. Make four scatterplots, with different variables (different columns) on the x and y axes, with the variable `quality` on the colour axis. For each scatterplot, choose a different pair of x and y variables, which cannot include `quality`. [1 mark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf2641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05592aac",
   "metadata": {},
   "source": [
    "15. Print the Pearson correlation between the pairs of variables you have included in the scatterplots. \n",
    "For every pair of variables, print the names of the variables, and the corresponding correlation. \n",
    "[1 mark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969168e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c292ca4",
   "metadata": {},
   "source": [
    "16. Linear regression: [2 marks]\n",
    "    \n",
    "a) Choosing the input variable X corresponds to any three columns of the dataset, except for `quality`, and the variable y corresponds to the `quality` column.\n",
    "\n",
    "b) Fit a linear regression between X and y.\n",
    "\n",
    "c) Print out the R2 score of the linear regression.\n",
    "\n",
    "d) Print out the linear regression model’s slope coefficients and intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc555a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c171081",
   "metadata": {},
   "source": [
    "17. K-fold cross-validation [3 marks]\n",
    "\n",
    "a) Using the same X and y variables defined in the question above, perform a K-fold cross-validation of the linear regression model, with K = 10.\n",
    "\n",
    "b) For each fold, calculate the R2 score.\n",
    "\n",
    "c) Print the mean and standard deviation of the five R2 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a07fc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331ea160",
   "metadata": {},
   "source": [
    "18.\tIf, rather than choosing three columns, you had used more columns to predict quality, would the R2 score of your model necessarily be higher? Why/why not? In which circumstances would it be higher or not? (Feel free to try it! But please provide a justification for your answer) [3 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3442d368",
   "metadata": {},
   "source": [
    "**>>> Answer by editing this cell (double-click here)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b393b486",
   "metadata": {},
   "source": [
    "19.\tImagine you have two linear regressions, one with R2 = 0.80 and another with R2 = 0.90. Under what circumstances would the first model be preferable over the second one? What if instead you had two classifiers, one with accuracy = 80% and another with accuracy = 90%? [3 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d431b2cb",
   "metadata": {},
   "source": [
    "**>>> Answer by editing this cell (double-click here)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08803e3b",
   "metadata": {},
   "source": [
    "_____________________\n",
    "\n",
    "# Part D – Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06caede4",
   "metadata": {},
   "source": [
    "20. K-means clustering:\n",
    "\n",
    "a) Read the file `dataset3.csv` into a dataframe.\n",
    "\n",
    "b) Define a variable X corresponding to the `Longitude` and `Latitude` columns of the dataset.\n",
    "\n",
    "c) Using the K-means clustering algorithm and the variable X, cluster the trees 3 times, using k = 5, 10, 15.\n",
    "\n",
    "d) Make a scatterplot showing the results of each clustering, with one colour for each cluster.\n",
    "Suggestion: use a categorical colour map such as tab10 or tab20.\n",
    "[2 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56fa082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981395ef",
   "metadata": {},
   "source": [
    "21. DBSCAN clustering:\n",
    "\n",
    "a) Using the same X variable as above, using the DBSCAN clustering algorithm, cluster the trees a total of 4 times, setting the eps parameter to 0.001, 0.005, 0.01, 0.05.\n",
    "\n",
    "b) Make a scatterplot showing the results of each clustering, with one colour for each cluster. \n",
    "Suggestion: use a categorical colour map such as tab10 or tab20.\n",
    "[2 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46213107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980d825f",
   "metadata": {},
   "source": [
    "22. Using the Silhouette score, compare the 3 runs of K-means and the 4 runs of DBSCAN. Which one of the 7 runs produces the \n",
    "best clustering, according to the Silhouette score? [2 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537f9553",
   "metadata": {},
   "source": [
    "23. Using the Davies-Bouldin score, compare the 3 runs of K-means and the 4 runs of DBSCAN. Which one of the 7 runs produces the best clustering according to the Davies-Bouldin score? [2 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73811579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a45102",
   "metadata": {},
   "source": [
    "24. Using another clustering algorithm (not K-means, not DBSCAN), and a range of hyperparameter values if appropriate, cluster the trees according to their latitude and longitude, as above. According to the silhouette and Davies-Bouldin scores, does any of your model runs produce better clustering? [2 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fb0f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15d7b2b",
   "metadata": {},
   "source": [
    "25. Usually, DBSCAN takes longer than K-means to run, and the time it takes to run is affected by the eps parameter. Explain why that is the case. [4 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5255ac",
   "metadata": {},
   "source": [
    "**>>> Answer by editing this cell (double-click here)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccda580",
   "metadata": {},
   "source": [
    "26. Provide an example of one case in which it might be better to use DBSCAN rather than K-means, and an example of one case in which it might be better to use K-means rather than DBSCAN. Explain why, in both cases. [4 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142c90f7",
   "metadata": {},
   "source": [
    "**>>> Answer by editing this cell (double-click here)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60736e7a",
   "metadata": {},
   "source": [
    "_____________________\n",
    "\n",
    "# Part E – Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8a060e",
   "metadata": {},
   "source": [
    "27. Consider the figure in the PDF and compare models A and B. In each case, what difference would it make to add more training examples to the training set? Explain your reasoning. [4 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f14256",
   "metadata": {},
   "source": [
    "**>>> Answer by editing this cell (double-click here)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe625689",
   "metadata": {},
   "source": [
    "28.\tConsider the second figure in the PDF and compare models A, B, and C. What is the difference between the three models? How does that relate to the bias-variance trade-off? [6 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c104388",
   "metadata": {},
   "source": [
    "**>>> Answer by editing this cell (double-click here)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c888301",
   "metadata": {},
   "source": [
    "29.\tWhat is overfitting? Why is that a problem, and how can one avoid it? [3 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228a25f2",
   "metadata": {},
   "source": [
    "**>>> Answer by editing this cell (double-click here)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb44b820",
   "metadata": {},
   "source": [
    "________________\n",
    "\n",
    "# Part F – Dimensionality reduction\n",
    "\n",
    "Consider a scenario where you are working with a complex high-dimensional dataset derived from a biomedical application to detect a disease. The data is expected to have both linear and non-linear relationships, and you aim to reduce the dimensionality for the following purposes: first, to visualize the data in a lower-dimensional space to identify potential clusters or patterns that might indicate different disease states, and second, to preprocess the data for a downstream machine learning task, such as classification of samples into healthy or diseased states. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d00a1fa",
   "metadata": {},
   "source": [
    "30.\tDiscuss the advantages and disadvantages of using PCA, t-SNE, and UMAP for the visualization purpose, considering factors such as the preservation of local and global structures, computational efficiency, and the potential introduction of artifacts. [3 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a09af9d",
   "metadata": {},
   "source": [
    "**>>> Answer by editing this cell (double-click here)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113f101a",
   "metadata": {},
   "source": [
    "31.\tExplain how the choice between these dimensionality reduction techniques might change when, after visualising, you want to do the preprocessing for the machine learning task. [3 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e84261",
   "metadata": {},
   "source": [
    "**>>> Answer by editing this cell (double-click here)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ac8f74",
   "metadata": {},
   "source": [
    "32.\tDiscuss the role of interpretability and stability in the choice of dimensionality reduction technique for both tasks. How might the stochastic nature of t-SNE and UMAP influence the reproducibility of your analyses, and how can PCA's linear assumptions limit its usefulness in capturing complex relationships in the data? [3 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19df64f3",
   "metadata": {},
   "source": [
    "**>>> Answer by editing this cell (double-click here)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7f2f08",
   "metadata": {},
   "source": [
    "________________\n",
    "\n",
    "# Part G – Applications of Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3155c82f",
   "metadata": {},
   "source": [
    "33.\tDiscuss a scenario where a high accuracy rate might be misleading in evaluating the performance of a classifier. What other metrics would you consider, and why? [3 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c2e59c",
   "metadata": {},
   "source": [
    "**>>> Answer by editing this cell (double-click here)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b1e46a",
   "metadata": {},
   "source": [
    "34. Given a classification task and a dataset, sometimes it’s impossible to make a classifier with 100% precision and 100% recall simultaneously. Explain why. [3 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f07d4e",
   "metadata": {},
   "source": [
    "**>>> Answer by editing this cell (double-click here)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22370410",
   "metadata": {},
   "source": [
    "35. In the case of the question above, the data scientist might have to choose between having higher precision or higher recall. Provide an example where it’s preferable to get high recall and low precision (and explain why), and another example where it’s preferable to have high precision and low recall (and explain why). [4 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157ec32b",
   "metadata": {},
   "source": [
    "**>>> Answer by editing this cell (double-click here)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5259805a",
   "metadata": {},
   "source": [
    "Over this module we explained many examples where a machine learning algorithm was trained on a dataset and became reasonably good at a task, but had a fundamental flaw in its training dataset or feature engineering that ultimately made the model inaccurate or inappropriate for use in real life.\n",
    "\n",
    "36. Give an example of a machine learning algorithm trained for a particular task where it achieves high accuracy in one context, but low accuracy in another context. Explain what could cause that, how to diagnose it, and suggest a way to address it. [4 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb71803d",
   "metadata": {},
   "source": [
    "**>>> Answer by editing this cell (double-click here)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a40ee58",
   "metadata": {},
   "source": [
    "37. Give an example of a machine learning algorithm that might have low errorin its training and testing datasets, but that still would have a fundamental flaw in its application that is not captured by the error metric. Explain why that is the case, and suggest a way to address that. [3 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7674d7b",
   "metadata": {},
   "source": [
    "**>>> Answer by editing this cell (double-click here)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba856c6",
   "metadata": {},
   "source": [
    "_________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
